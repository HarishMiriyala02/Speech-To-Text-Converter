# -*- coding: utf-8 -*-
"""Speech_To_Text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iys__jc5Zx39ZOoe17mftWHBK1bggBRp

Install Required Libraries
"""

!pip install gradio torchaudio transformers soundfile scipy

"""Import Dependencies"""

import torch
import torchaudio
import soundfile as sf
import gradio as gr
import numpy as np
import time
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor

"""Load Pretrained Model"""

# Load Wav2Vec2 base model and processor from Hugging Face
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")
model.eval()

"""Define Chunked Transcription Function

This function simulates “real-time” transcription by processing audio in short chunks (e.g. 2 seconds).
"""

def transcribe_in_chunks(audio_file):
    # Load the audio
    speech, sample_rate = torchaudio.load(audio_file)

    # Resample if not 16000Hz
    if sample_rate != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
        speech = resampler(speech)
        sample_rate = 16000

    # Set chunk size (2 seconds = 2 * 16000 samples)
    chunk_size = 2 * sample_rate
    total_samples = speech.shape[1]

    full_transcription = ""

    for i in range(0, total_samples, chunk_size):
        chunk = speech[:, i:i+chunk_size]
        if chunk.shape[1] < 1000:  # Skip too small chunks
            continue

        inputs = processor(chunk.squeeze(), sampling_rate=sample_rate, return_tensors="pt", padding=True)
        with torch.no_grad():
            logits = model(inputs.input_values).logits

        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.decode(predicted_ids[0])
        full_transcription += transcription + " "

    # Save transcript and audio
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    text_filename = f"transcript_{timestamp}.txt"
    with open(text_filename, "w") as f:
        f.write(full_transcription.strip())

    return full_transcription.strip()

"""Create and Launch Gradio Interface"""

# Create Gradio interface using default Audio input (mic) without 'source' argument
interface = gr.Interface(
    fn=transcribe_in_chunks,
    inputs=gr.Audio(type="filepath", label="Record Your Voice"),
    outputs=gr.Textbox(label="Transcription"),
    title="Real-Time Chunked Speech-to-Text",
    description="Speak into your microphone. This app processes your speech in chunks for better real-time transcription feel."
)

interface.launch(share=True)